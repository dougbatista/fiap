{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238a115d-f26e-46f3-b250-4f93649107b2",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3cd6b9-caec-4dae-8f2a-828f136f3244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data_tweet</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jan 08 01:22:05 +0000 2017</td>\n",
       "      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jan 08 01:49:01 +0000 2017</td>\n",
       "      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sun Jan 08 01:01:46 +0000 2017</td>\n",
       "      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wed Jan 04 21:43:51 +0000 2017</td>\n",
       "      <td>��� https://t.co/BnDsO34qK0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jan 09 15:08:21 +0000 2017</td>\n",
       "      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      data_tweet  \\\n",
       "0   0  Sun Jan 08 01:22:05 +0000 2017   \n",
       "1   1  Sun Jan 08 01:49:01 +0000 2017   \n",
       "2   2  Sun Jan 08 01:01:46 +0000 2017   \n",
       "3   3  Wed Jan 04 21:43:51 +0000 2017   \n",
       "4   4  Mon Jan 09 15:08:21 +0000 2017   \n",
       "\n",
       "                                               texto sentimento  \n",
       "0  ���⛪ @ Catedral de Santo Antônio - Governador ...     Neutro  \n",
       "1  � @ Governador Valadares, Minas Gerais https:/...     Neutro  \n",
       "2  �� @ Governador Valadares, Minas Gerais https:...     Neutro  \n",
       "3                        ��� https://t.co/BnDsO34qK0     Neutro  \n",
       "4  ��� PSOL vai questionar aumento de vereadores ...   Negativo  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://dados-ml-pln.s3.sa-east-1.amazonaws.com/tweets_classificados.csv\", encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16438df8-d978-4680-8049-70093533fd0e",
   "metadata": {},
   "source": [
    "## ToDo 1\n",
    "\n",
    "Altere as funções de tratamento de texto apresentadas em sala para que elas façam a remoção de links também. \n",
    "\n",
    "Crie uma nova coluna chamada texto_tratado que conterá o resultado da aplicação das funções. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09d7e0e-4d25-4d51-83a4-c509b89ac1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resposta\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "    \n",
    "        \n",
    "def normalize_accents(text):\n",
    "    return unicodedata.normalize(\"NFKD\", text).encode(\"ASCII\", \"ignore\").decode(\"utf-8\")\n",
    "\n",
    "def normalize_str(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)\", \" \",text) #remove links\n",
    "    text = remove_punctuation(text)\n",
    "    text = normalize_accents(text)\n",
    "    text = re.sub(re.compile(r\" +\"), \" \",text)\n",
    "    return \" \".join([w for w in text.split()])\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuations = string.punctuation\n",
    "    table = str.maketrans({key: \" \" for key in punctuations})\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    stop_words = nltk.corpus.stopwords.words(\"english\") # portuguese, caso o dataset seja em português\n",
    "    if isinstance(text, str):\n",
    "        text = normalize_str(text)\n",
    "        text = \"\".join([w for w in text if not w.isdigit()])\n",
    "        text = word_tokenize(text)\n",
    "        text = [x for x in text if x not in stop_words]\n",
    "        text = [y for y in text if len(y) > 2]\n",
    "        return \" \".join([t for t in text])\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd995a8-7b9d-4dee-83a0-d79ea798be92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['texto_tratado'] = df['texto'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a285105-f7b9-4780-900b-8edd6595fa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data_tweet</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "      <th>texto_tratado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jan 08 01:22:05 +0000 2017</td>\n",
       "      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>catedral santo antonio governador valadares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jan 08 01:49:01 +0000 2017</td>\n",
       "      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>governador valadares minas gerais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sun Jan 08 01:01:46 +0000 2017</td>\n",
       "      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>governador valadares minas gerais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wed Jan 04 21:43:51 +0000 2017</td>\n",
       "      <td>��� https://t.co/BnDsO34qK0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jan 09 15:08:21 +0000 2017</td>\n",
       "      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>psol vai questionar aumento vereadores prefeit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      data_tweet  \\\n",
       "0   0  Sun Jan 08 01:22:05 +0000 2017   \n",
       "1   1  Sun Jan 08 01:49:01 +0000 2017   \n",
       "2   2  Sun Jan 08 01:01:46 +0000 2017   \n",
       "3   3  Wed Jan 04 21:43:51 +0000 2017   \n",
       "4   4  Mon Jan 09 15:08:21 +0000 2017   \n",
       "\n",
       "                                               texto sentimento  \\\n",
       "0  ���⛪ @ Catedral de Santo Antônio - Governador ...     Neutro   \n",
       "1  � @ Governador Valadares, Minas Gerais https:/...     Neutro   \n",
       "2  �� @ Governador Valadares, Minas Gerais https:...     Neutro   \n",
       "3                        ��� https://t.co/BnDsO34qK0     Neutro   \n",
       "4  ��� PSOL vai questionar aumento de vereadores ...   Negativo   \n",
       "\n",
       "                                       texto_tratado  \n",
       "0        catedral santo antonio governador valadares  \n",
       "1                  governador valadares minas gerais  \n",
       "2                  governador valadares minas gerais  \n",
       "3                                                     \n",
       "4  psol vai questionar aumento vereadores prefeit...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c91a5c5-c909-4af7-8b9e-3a6e224f0d23",
   "metadata": {},
   "source": [
    "## ToDo 2\n",
    "\n",
    "Ao fazer a remoção de links, percebemos que algumas linhas da coluna texto_tratado possuem valores faltantes. Entretanto, o Python trata eles como ''(str) e nao como Null. Assim, um simples dropna nao resolve o problema. \n",
    "\n",
    "Encontre uma forma de remover tais elementos. Dica: use o índice das linhas cujos elementos da coluna texto_tratado seja nulo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9297ec43-a5ac-4f48-b3cb-284b5b8a8ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5055: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>data_tweet</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "      <th>texto_tratado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jan 08 01:22:05 +0000 2017</td>\n",
       "      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>catedral santo antonio governador valadares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jan 08 01:49:01 +0000 2017</td>\n",
       "      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>governador valadares minas gerais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Sun Jan 08 01:01:46 +0000 2017</td>\n",
       "      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>governador valadares minas gerais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jan 09 15:08:21 +0000 2017</td>\n",
       "      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>psol vai questionar aumento vereadores prefeit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Sat Jan 07 13:47:55 +0000 2017</td>\n",
       "      <td>\" bom é bandido morto\"\\nDeputado Cabo Júlio é ...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>bom bandido morto deputado cabo julio condenad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id                      data_tweet  \\\n",
       "0      0   0  Sun Jan 08 01:22:05 +0000 2017   \n",
       "1      1   1  Sun Jan 08 01:49:01 +0000 2017   \n",
       "2      2   2  Sun Jan 08 01:01:46 +0000 2017   \n",
       "3      4   4  Mon Jan 09 15:08:21 +0000 2017   \n",
       "4      5   5  Sat Jan 07 13:47:55 +0000 2017   \n",
       "\n",
       "                                               texto sentimento  \\\n",
       "0  ���⛪ @ Catedral de Santo Antônio - Governador ...     Neutro   \n",
       "1  � @ Governador Valadares, Minas Gerais https:/...     Neutro   \n",
       "2  �� @ Governador Valadares, Minas Gerais https:...     Neutro   \n",
       "3  ��� PSOL vai questionar aumento de vereadores ...   Negativo   \n",
       "4  \" bom é bandido morto\"\\nDeputado Cabo Júlio é ...     Neutro   \n",
       "\n",
       "                                       texto_tratado  \n",
       "0        catedral santo antonio governador valadares  \n",
       "1                  governador valadares minas gerais  \n",
       "2                  governador valadares minas gerais  \n",
       "3  psol vai questionar aumento vereadores prefeit...  \n",
       "4  bom bandido morto deputado cabo julio condenad...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resposta\n",
    "import numpy as np\n",
    "df = df.drop(df.index[[list(np.where(df['texto_tratado']==''))[0]]]).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02182587-d569-47b6-b7af-19404429c16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df['texto_tratado']=='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657c5a9-de70-4500-b2ef-b28065659888",
   "metadata": {},
   "source": [
    "## ToDo 3\n",
    "\n",
    "Separe a coluna texto_tratado em conjunto de treino e teste na proporção 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9a01f6-af94-4b98-9091-94b08ccc48f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide o dataframe em amostras de treino e teste\n",
    "df_train, df_test = train_test_split(\n",
    "      df, \n",
    "      test_size = 0.3, \n",
    "      random_state = 42\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7434514-3e94-4d8d-abd3-f711bbada875",
   "metadata": {},
   "source": [
    "## ToDo 4\n",
    "\n",
    "Transforme os dados para criar a representação numérica dos textos. Use uma versão com CountVectorizer e outra com TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64278ca9-3618-4002-a4d5-8b95803c70ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resposta - CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,2))   \n",
    "cv.fit(df_train.texto_tratado)\n",
    "x_train_cv = cv.transform(df_train.texto_tratado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9017f885-b3cb-4cfa-88f7-5dc7f52bd668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resposta - TFIDFVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1))   \n",
    "tfidf.fit(df_train.texto_tratado)\n",
    "x_train_tf = tfidf.transform(df_train.texto_tratado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfb366-1e15-433a-a6e6-00ebe3f0844f",
   "metadata": {},
   "source": [
    "## ToDo 5\n",
    "\n",
    "Treine uma árvore de decisão nas duas abordagens e compare seus resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0925a9b3-ffd2-40cf-86ca-5a75c02ecd9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9247685185185185\n"
     ]
    }
   ],
   "source": [
    "# resposta - CountVecorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train = df_train[\"sentimento\"]\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(x_train_cv, y_train)\n",
    "\n",
    "x_test = cv.transform(df_test.texto_tratado)\n",
    "y_prediction = tree.predict(x_test)\n",
    "\n",
    "y_test = df_test[\"sentimento\"]\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ea2e86-2685-426b-aad2-b58a75b9000f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9085648148148148\n"
     ]
    }
   ],
   "source": [
    "# resposta - TFIDFVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train = df_train[\"sentimento\"]\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(x_train_tf, y_train)\n",
    "\n",
    "x_test = tfidf.transform(df_test.texto_tratado)\n",
    "y_prediction = tree.predict(x_test)\n",
    "\n",
    "y_test = df_test[\"sentimento\"]\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c2477-5e10-4d3a-a5e7-477812b5629f",
   "metadata": {},
   "source": [
    "## ToDo 6\n",
    "Crie uma função que lematiza as palavras da coluna texto_tratado apenas se elas forem um verbo. Depois, crie uma nova coluna chamada texto_tratado_lemma que conterá o resultado da aplicação da função na coluna texto_tratado. \n",
    "\n",
    "Dica: use o Corpus pt_core_news_sm como referência para determinar a classe gramatical da palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f3a4b60-42c0-4597-b839-21da6618ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.4.3-cp39-cp39-win_amd64.whl (11.9 MB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.5-cp39-cp39-win_amd64.whl (1.3 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.10\n",
      "  Downloading spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.2-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.10.0-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.5-cp39-cp39-win_amd64.whl (481 kB)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.3-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: catalogue, srsly, pydantic, murmurhash, cymem, wasabi, typer, smart-open, preshed, confection, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 5.1.0\n",
      "    Uninstalling smart-open-5.1.0:\n",
      "      Successfully uninstalled smart-open-5.1.0\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.3 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.0 preshed-3.0.8 pydantic-1.10.2 smart-open-5.2.1 spacy-3.4.3 spacy-legacy-3.0.10 spacy-loggers-1.0.3 srsly-2.4.5 thinc-8.1.5 typer-0.7.0 wasabi-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d206a545-6d9b-43d3-b288-8bebba1658a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.4.0/pt_core_news_sm-3.4.0-py3-none-any.whl (13.0 MB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pt-core-news-sm==3.4.0) (3.4.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.10.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.1)\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.4.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 19:09:14.789148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-11-28 19:09:14.789194: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-28 19:09:19.063296: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2022-11-28 19:09:19.063328: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-28 19:09:19.067243: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: PA702MICRO100\n",
      "2022-11-28 19:09:19.067387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: PA702MICRO100\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dec1f603-2481-47bd-b4e1-95dc5bba803d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resposta\n",
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "def lemmatizer_verbs(text):\n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        if word.pos_ == \"VERB\":\n",
    "            sent.append(word.lemma_)\n",
    "        else:\n",
    "            sent.append(word.text)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73cc4123-aa39-4d2f-bd34-2afdbe9a2605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['texto_tratado_lemma'] = df.texto_tratado.apply(lemmatizer_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e41c2e-e1ea-4573-a28b-31e1a3a4008a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>data_tweet</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "      <th>texto_tratado</th>\n",
       "      <th>texto_tratado_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jan 08 01:22:05 +0000 2017</td>\n",
       "      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>catedral santo antonio governador valadares</td>\n",
       "      <td>catedral santo antonio governador valadares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jan 08 01:49:01 +0000 2017</td>\n",
       "      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>governador valadares minas gerais</td>\n",
       "      <td>governador valadar minas gerais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Sun Jan 08 01:01:46 +0000 2017</td>\n",
       "      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>governador valadares minas gerais</td>\n",
       "      <td>governador valadar minas gerais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jan 09 15:08:21 +0000 2017</td>\n",
       "      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>psol vai questionar aumento vereadores prefeit...</td>\n",
       "      <td>psol vai questionar aumento vereadores prefeit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Sat Jan 07 13:47:55 +0000 2017</td>\n",
       "      <td>\" bom é bandido morto\"\\nDeputado Cabo Júlio é ...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>bom bandido morto deputado cabo julio condenad...</td>\n",
       "      <td>bom bandido morrer deputado cabo julio condena...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id                      data_tweet  \\\n",
       "0      0   0  Sun Jan 08 01:22:05 +0000 2017   \n",
       "1      1   1  Sun Jan 08 01:49:01 +0000 2017   \n",
       "2      2   2  Sun Jan 08 01:01:46 +0000 2017   \n",
       "3      4   4  Mon Jan 09 15:08:21 +0000 2017   \n",
       "4      5   5  Sat Jan 07 13:47:55 +0000 2017   \n",
       "\n",
       "                                               texto sentimento  \\\n",
       "0  ���⛪ @ Catedral de Santo Antônio - Governador ...     Neutro   \n",
       "1  � @ Governador Valadares, Minas Gerais https:/...     Neutro   \n",
       "2  �� @ Governador Valadares, Minas Gerais https:...     Neutro   \n",
       "3  ��� PSOL vai questionar aumento de vereadores ...   Negativo   \n",
       "4  \" bom é bandido morto\"\\nDeputado Cabo Júlio é ...     Neutro   \n",
       "\n",
       "                                       texto_tratado  \\\n",
       "0        catedral santo antonio governador valadares   \n",
       "1                  governador valadares minas gerais   \n",
       "2                  governador valadares minas gerais   \n",
       "3  psol vai questionar aumento vereadores prefeit...   \n",
       "4  bom bandido morto deputado cabo julio condenad...   \n",
       "\n",
       "                                 texto_tratado_lemma  \n",
       "0        catedral santo antonio governador valadares  \n",
       "1                    governador valadar minas gerais  \n",
       "2                    governador valadar minas gerais  \n",
       "3  psol vai questionar aumento vereadores prefeit...  \n",
       "4  bom bandido morrer deputado cabo julio condena...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f00ad-56d7-40d4-857b-1156c6f77bc3",
   "metadata": {},
   "source": [
    "## ToDo 7\n",
    "\n",
    "repita os ToDo 3, ToDo 4 e ToDo 5, usando como feature a coluna texto_tratado_lemma, e veja se os resultados tiveram melhora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e43f8ffe-358f-40a1-bed4-4470910c657d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "      df, \n",
    "      test_size = 0.3, \n",
    "      random_state = 42\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9237801-74d3-45bf-8c42-02776ff38cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#resposta - CountVectorizer\n",
    "cv2 = CountVectorizer(ngram_range=(1,1))   \n",
    "cv2.fit(df_train.texto_tratado_lemma)\n",
    "x_train_cv2 = cv2.transform(df_train.texto_tratado_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbef76f4-0099-478f-bf85-6ab91bc9148d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resposta - TFIDFVectorizer\n",
    "tfidf2 = TfidfVectorizer(ngram_range=(1,1))  \n",
    "tfidf2.fit(df_train.texto_tratado_lemma)\n",
    "x_train_tf2 = tfidf2.transform(df_train.texto_tratado_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f0b4b58-0b38-451a-8690-e645dd81e985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia com CV:  0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train[\"sentimento\"]\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(x_train_cv2, y_train)\n",
    "\n",
    "x_test = cv2.transform(df_test.texto_tratado_lemma)\n",
    "\n",
    "y_prediction = model.predict(x_test)\n",
    "\n",
    "y_test = df_test[\"sentimento\"]\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "print('Acurácia com CV: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8fc8a04-3821-44f4-99bf-02c69f707738",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia com TFIDF:  0.9033564814814815\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train[\"sentimento\"]\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(x_train_tf2, y_train)\n",
    "\n",
    "x_test = tfidf2.transform(df_test.texto_tratado_lemma)\n",
    "\n",
    "y_prediction = model.predict(x_test)\n",
    "\n",
    "y_test = df_test[\"sentimento\"]\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "print('Acurácia com TFIDF: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04833f75-32b9-4743-985d-d140576998f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
