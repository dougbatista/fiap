{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\programdata\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting pt-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.4.0/pt_core_news_sm-3.4.0-py3-none-any.whl (13.0 MB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pt-core-news-sm==3.4.0) (3.4.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.7.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.21.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.1)\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.4.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 19:07:06.156860: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-12-06 19:07:06.156905: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-06 19:07:10.297432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2022-12-06 19:07:10.297464: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-06 19:07:10.301541: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: PA702MICRO100\n",
      "2022-12-06 19:07:10.301714: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: PA702MICRO100\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega os Tweets classificados\n",
    "dfTweetsAux = pd.read_csv('dados/tweets_classificados.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\logonpflocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega StopWords\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# stopwords NLTK\n",
    "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "# stopwords SpaCy\n",
    "stops_spacy = nlp.Defaults.stop_words\n",
    "\n",
    "# stopwords do SpaCy e NLTK combinadas\n",
    "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de lematização completa do documento\n",
    "def fn_lematiza_texto(texto):\n",
    "    sent = []\n",
    "    doc = nlp(texto)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "        \n",
    "    return ' '.join(sent)\n",
    "\n",
    "# função de lematização dos verbos do documento\n",
    "def fn_lematiza_verb_texto(texto):\n",
    "    sent = []\n",
    "    doc = nlp(texto)\n",
    "    for word in doc:\n",
    "        if word.pos_ =='VERB':\n",
    "            sent.append(word.lemma_)\n",
    "        else:\n",
    "            sent.append(word.text)\n",
    "    return \" \".join(sent)\n",
    "\n",
    "\n",
    "# função para limpar documento\n",
    "def fn_limpa_texto(texto):\n",
    "    texto = re.sub(r'@\\w+','',texto)\n",
    "    texto = re.sub(r'#','',texto)\n",
    "    texto = re.sub(r'RT[\\s]+','',texto)  \n",
    "    #texto = re.sub(r'rt[\\s]+','',texto)  \n",
    "    texto = re.sub(r'https:/\\/\\S+','',texto)\n",
    "    texto = re.sub(r'[,.:;]','',texto)\n",
    "    texto = re.sub(r'\\n',' ',texto)\n",
    "    texto = re.sub(u'[^a-zA-ZâêîôûÂÊÎÔÛáéíóúÁÉÍÓÚàèìòùÀÈÌÒÙãõÃÕçÇ ]', '', texto)\n",
    "    texto = texto.strip().lower()\n",
    "    \n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplica normalização no dataframe\n",
    "dfTweetsAux['texto_trat'] = dfTweetsAux.texto.apply(fn_limpa_texto)\n",
    "\n",
    "# aplica a lematização no dataframe\n",
    "dfTweetsAux['texto_lemma'] = dfTweetsAux.texto_trat.apply(fn_lematiza_texto)\n",
    "\n",
    "# aplica a lematização dos verbos no dataframe\n",
    "dfTweetsAux['texto_lemma_verb'] = dfTweetsAux.texto_trat.apply(fn_lematiza_verb_texto)\n",
    "\n",
    "# apaga tweets nulos\n",
    "dfTweetsAux.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@sandroottoni_ Se ninguem entender deixa que a professora Julia ensina :)\n",
      "se ninguem entender deixa que a professora julia ensina\n",
      "se ninguir entender deixar que o professora julio ensina\n",
      "se ninguir entender deixar que a professora julia ensina\n"
     ]
    }
   ],
   "source": [
    "# analisa alguns dados\n",
    "print(dfTweetsAux['texto'][1])\n",
    "print(dfTweetsAux['texto_trat'][1])\n",
    "print(dfTweetsAux['texto_lemma'][1])\n",
    "print(dfTweetsAux['texto_lemma_verb'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo final\n",
    "\n",
    "# vetorização tf-idf com combinação de unigrama e bigrama\n",
    "vetor = TfidfVectorizer(ngram_range=(1,2), use_idf=True) \n",
    "\n",
    "# texto tratado e verbos lematizado\n",
    "vetor.fit(dfTweetsAux.texto_lemma_verb)\n",
    "text_vect = vetor.transform(dfTweetsAux.texto_lemma_verb)\n",
    "\n",
    "# separa as amostras de Treino (80%) e Texte (20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "        text_vect, \n",
    "        dfTweetsAux['sentimento'], \n",
    "        test_size = 0.2,\n",
    "        random_state = 42\n",
    "    )\n",
    "\n",
    "# define e treina o modelo de classificação\n",
    "modelo = SVC(kernel=\"rbf\", C=5, class_weight=\"balanced\")\n",
    "\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# valida a parformance\n",
    "y_prediction = modelo.predict(X_test)\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "\n",
    "print(text_vect.shape)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva modelo e vetor de bag of words\n",
    "import pickle\n",
    "\n",
    "pickle.dump(vetor, open('modelo_verorizacao.pkl', 'wb'))\n",
    "pickle.dump(modelo, open('modelo_classificacao.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
