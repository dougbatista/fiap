{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/CustomEnvironments/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from TextHandler import TextHandler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento de dados e definição de modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe TextHandler: Responsável pelo pré-processamento de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_handler = TextHandler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>O Bravo parece indicar que o personagem princi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Durante a Guerra pela Independência do Sul, GE...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Obra-prima absoluta de um filme! Boa noite Mr....</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Embora a palavra megalmania seja muito usada p...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Esta tem que ser a peça mais incrível de porca...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Eu suponho que todas as piadas internas são o ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Se há um tema deste filme, é que as pessoas po...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo                                              texto sentimento\n",
       "0       1  Esse bocejo de pia de cozinha de orçamento mui...        neg\n",
       "1       2  O Bravo parece indicar que o personagem princi...        neg\n",
       "2       3  Durante a Guerra pela Independência do Sul, GE...        pos\n",
       "3       4  É fora de questão que a verdadeira Anna Anders...        pos\n",
       "4       5  Concordo totalmente com outro dos revisores aq...        neg\n",
       "5       6  Obra-prima absoluta de um filme! Boa noite Mr....        pos\n",
       "6       7  Embora a palavra megalmania seja muito usada p...        pos\n",
       "7       8  Esta tem que ser a peça mais incrível de porca...        neg\n",
       "8       9  Eu suponho que todas as piadas internas são o ...        neg\n",
       "9      10  Se há um tema deste filme, é que as pessoas po...        pos"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reviews-pt-br.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    50.112324\n",
       "pos    49.887676\n",
       "Name: sentimento, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.sentimento.value_counts() / df.shape[0]) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformação da classe de sentimento para digitos binários (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentimento_codificado'] = le.fit_transform(df.sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "      <th>sentimento_codificado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>O Bravo parece indicar que o personagem princi...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Durante a Guerra pela Independência do Sul, GE...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo                                              texto sentimento  \\\n",
       "0       1  Esse bocejo de pia de cozinha de orçamento mui...        neg   \n",
       "1       2  O Bravo parece indicar que o personagem princi...        neg   \n",
       "2       3  Durante a Guerra pela Independência do Sul, GE...        pos   \n",
       "3       4  É fora de questão que a verdadeira Anna Anders...        pos   \n",
       "4       5  Concordo totalmente com outro dos revisores aq...        neg   \n",
       "\n",
       "   sentimento_codificado  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44514 entries, 0 to 44513\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   codigo                 44514 non-null  int64 \n",
      " 1   texto                  44514 non-null  object\n",
      " 2   sentimento             44514 non-null  object\n",
      " 3   sentimento_codificado  44514 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto_processado'] = df['texto'].apply(txt_handler.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação do dataset em teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['texto_processado'].copy()\n",
    "y = df['sentimento_codificado'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando CountVectorizer para extração de features do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<35611x2415006 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7772018 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,2)) \n",
    "vect.fit(X_train)\n",
    "X_train_count_vec = vect.transform(X_train)\n",
    "X_train_count_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8903x2415006 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1455957 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_count_vec = vect.transform(X_test)\n",
    "X_test_count_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_count_vec.A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando TfidfVectorizer para extração de features do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_id_vec = TfidfVectorizer(lowercase=False,ngram_range=(1,1))\n",
    "tf_id_vec.fit(X_train)\n",
    "X_train_id_vec = tf_id_vec.transform(X_train)\n",
    "\n",
    "X_test_id_vec = tf_id_vec.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(max_depth=8, random_state=42)\n",
    "clf2 = GradientBoostingClassifier(learning_rate=0.01, random_state=42)\n",
    "clf3 = AdaBoostClassifier(random_state=42)\n",
    "clf4 = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('rf', clf1), ('gbc', clf2), ('abc', clf3), ('lr', clf4)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(max_depth=8,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;gbc&#x27;,\n",
       "                              GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                         random_state=42)),\n",
       "                             (&#x27;abc&#x27;, AdaBoostClassifier(random_state=42)),\n",
       "                             (&#x27;lr&#x27;, LogisticRegression(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(max_depth=8,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;gbc&#x27;,\n",
       "                              GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                         random_state=42)),\n",
       "                             (&#x27;abc&#x27;, AdaBoostClassifier(random_state=42)),\n",
       "                             (&#x27;lr&#x27;, LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>abc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(max_depth=8,\n",
       "                                                     random_state=42)),\n",
       "                             ('gbc',\n",
       "                              GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                         random_state=42)),\n",
       "                             ('abc', AdaBoostClassifier(random_state=42)),\n",
       "                             ('lr', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1.fit(X_train_id_vec, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função compare_models criada para comparar modelos dinamicamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "def compare_models(X_train, y_train, X_test, y_test, models = []):\n",
    "  for clf in models:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat = clf.predict(X_test)\n",
    "    cr = classification_report(y_test, y_hat)\n",
    "    print(\"Classificador: {} \\n {}\".format(clf.__class__.__name__, cr))\n",
    "    print(\"F1 SCORE: \", f1_score(y_test, y_hat, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação de modelos utilizando CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador: RandomForestClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      4470\n",
      "           1       0.77      0.81      0.79      4433\n",
      "\n",
      "    accuracy                           0.79      8903\n",
      "   macro avg       0.79      0.79      0.79      8903\n",
      "weighted avg       0.79      0.79      0.79      8903\n",
      "\n",
      "F1 SCORE:  0.7872615212903785\n",
      "Classificador: GradientBoostingClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.48      0.60      4470\n",
      "           1       0.63      0.90      0.74      4433\n",
      "\n",
      "    accuracy                           0.69      8903\n",
      "   macro avg       0.73      0.69      0.67      8903\n",
      "weighted avg       0.73      0.69      0.67      8903\n",
      "\n",
      "F1 SCORE:  0.6724572668853234\n",
      "Classificador: AdaBoostClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      4470\n",
      "           1       0.77      0.84      0.80      4433\n",
      "\n",
      "    accuracy                           0.80      8903\n",
      "   macro avg       0.80      0.80      0.80      8903\n",
      "weighted avg       0.80      0.80      0.80      8903\n",
      "\n",
      "F1 SCORE:  0.7953020170058739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/CustomEnvironments/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador: LogisticRegression \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      4470\n",
      "           1       0.89      0.90      0.90      4433\n",
      "\n",
      "    accuracy                           0.89      8903\n",
      "   macro avg       0.90      0.90      0.89      8903\n",
      "weighted avg       0.90      0.89      0.89      8903\n",
      "\n",
      "F1 SCORE:  0.8949727093986474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/CustomEnvironments/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador: VotingClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      4470\n",
      "           1       0.85      0.86      0.86      4433\n",
      "\n",
      "    accuracy                           0.86      8903\n",
      "   macro avg       0.86      0.86      0.86      8903\n",
      "weighted avg       0.86      0.86      0.86      8903\n",
      "\n",
      "F1 SCORE:  0.8567899725926661\n"
     ]
    }
   ],
   "source": [
    "compare_models(X_train_count_vec, y_train, X_test_count_vec, y_test, [clf1, clf2, clf3, clf4, eclf1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação de modelos utilizando TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador: RandomForestClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      4470\n",
      "           1       0.80      0.82      0.81      4433\n",
      "\n",
      "    accuracy                           0.81      8903\n",
      "   macro avg       0.81      0.81      0.81      8903\n",
      "weighted avg       0.81      0.81      0.81      8903\n",
      "\n",
      "F1 SCORE:  0.8074564310040091\n",
      "Classificador: GradientBoostingClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.53      0.64      4470\n",
      "           1       0.65      0.88      0.75      4433\n",
      "\n",
      "    accuracy                           0.71      8903\n",
      "   macro avg       0.74      0.71      0.70      8903\n",
      "weighted avg       0.74      0.71      0.70      8903\n",
      "\n",
      "F1 SCORE:  0.6959015312278457\n",
      "Classificador: AdaBoostClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79      4470\n",
      "           1       0.78      0.83      0.80      4433\n",
      "\n",
      "    accuracy                           0.80      8903\n",
      "   macro avg       0.80      0.80      0.80      8903\n",
      "weighted avg       0.80      0.80      0.80      8903\n",
      "\n",
      "F1 SCORE:  0.795753265602475\n",
      "Classificador: LogisticRegression \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      4470\n",
      "           1       0.87      0.91      0.89      4433\n",
      "\n",
      "    accuracy                           0.89      8903\n",
      "   macro avg       0.89      0.89      0.89      8903\n",
      "weighted avg       0.89      0.89      0.89      8903\n",
      "\n",
      "F1 SCORE:  0.8860715459157344\n",
      "Classificador: VotingClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4470\n",
      "           1       0.85      0.85      0.85      4433\n",
      "\n",
      "    accuracy                           0.85      8903\n",
      "   macro avg       0.85      0.85      0.85      8903\n",
      "weighted avg       0.85      0.85      0.85      8903\n",
      "\n",
      "F1 SCORE:  0.8466802983021073\n"
     ]
    }
   ],
   "source": [
    "compare_models(X_train_id_vec, y_train, X_test_id_vec, y_test, [clf1, clf2, clf3, clf4, eclf1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texto Lematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['texto_lematizado'] = df['texto_processado'].apply(txt_handler.lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('df_completo.csv') # Salvar a versão lematizada em .csv porque demora muito para processar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lematizado = pd.read_csv('df_completo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>codigo</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "      <th>sentimento_codificado</th>\n",
       "      <th>texto_processado</th>\n",
       "      <th>texto_lematizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>bocejo pia cozinha orcamento baixo tipo filme ...</td>\n",
       "      <td>bocejo pia cozinhar orcamento baixo tipo filme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>O Bravo parece indicar que o personagem princi...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>bravo parece indicar personagem principal clar...</td>\n",
       "      <td>bravo parecer indicar personagem principal cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Durante a Guerra pela Independência do Sul, GE...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>durante guerra independencia sul general spank...</td>\n",
       "      <td>durante guerra independencia sul general spank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>questao verdadeira anna anderson nao princesa ...</td>\n",
       "      <td>questao verdadeira anna anderson nao princesa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>concordo totalmente outro revisores aqui ficou...</td>\n",
       "      <td>concordo totalmente outro revisores aqui ficar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  codigo                                              texto  \\\n",
       "0           0       1  Esse bocejo de pia de cozinha de orçamento mui...   \n",
       "1           1       2  O Bravo parece indicar que o personagem princi...   \n",
       "2           2       3  Durante a Guerra pela Independência do Sul, GE...   \n",
       "3           3       4  É fora de questão que a verdadeira Anna Anders...   \n",
       "4           4       5  Concordo totalmente com outro dos revisores aq...   \n",
       "\n",
       "  sentimento  sentimento_codificado  \\\n",
       "0        neg                      0   \n",
       "1        neg                      0   \n",
       "2        pos                      1   \n",
       "3        pos                      1   \n",
       "4        neg                      0   \n",
       "\n",
       "                                    texto_processado  \\\n",
       "0  bocejo pia cozinha orcamento baixo tipo filme ...   \n",
       "1  bravo parece indicar personagem principal clar...   \n",
       "2  durante guerra independencia sul general spank...   \n",
       "3  questao verdadeira anna anderson nao princesa ...   \n",
       "4  concordo totalmente outro revisores aqui ficou...   \n",
       "\n",
       "                                    texto_lematizado  \n",
       "0  bocejo pia cozinhar orcamento baixo tipo filme...  \n",
       "1  bravo parecer indicar personagem principal cla...  \n",
       "2  durante guerra independencia sul general spank...  \n",
       "3  questao verdadeira anna anderson nao princesa ...  \n",
       "4  concordo totalmente outro revisores aqui ficar...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lematizado.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação do dataset em teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lematizado = df_lematizado['texto_lematizado'].copy()\n",
    "y_2 = df_lematizado['sentimento_codificado'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lematizado, y_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando CountVectorizer para extração de features do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2)) \n",
    "vect.fit(X_train)\n",
    "X_train_count_vec_lemma = vect.transform(X_train)\n",
    "X_test_count_vec_lemma = vect.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando CountVectorizer para extração de features do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_id_vec = TfidfVectorizer(lowercase=False, ngram_range=(1,1))\n",
    "tf_id_vec.fit(X_train)\n",
    "X_train_id_vec_lemma = tf_id_vec.transform(X_train)\n",
    "X_test_id_vec_lemma = tf_id_vec.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=8, random_state=42)\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.01, random_state=42)\n",
    "abc = AdaBoostClassifier(random_state=42)\n",
    "ls = LogisticRegression(random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação de modelos utilizando CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador: RandomForestClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      4470\n",
      "           1       0.79      0.82      0.81      4433\n",
      "\n",
      "    accuracy                           0.80      8903\n",
      "   macro avg       0.81      0.80      0.80      8903\n",
      "weighted avg       0.81      0.80      0.80      8903\n",
      "\n",
      "F1 SCORE:  0.8047444377243197\n",
      "Classificador: GradientBoostingClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.49      0.61      4470\n",
      "           1       0.63      0.90      0.74      4433\n",
      "\n",
      "    accuracy                           0.69      8903\n",
      "   macro avg       0.73      0.69      0.68      8903\n",
      "weighted avg       0.73      0.69      0.68      8903\n",
      "\n",
      "F1 SCORE:  0.6763603240498278\n",
      "Classificador: AdaBoostClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78      4470\n",
      "           1       0.77      0.84      0.80      4433\n",
      "\n",
      "    accuracy                           0.79      8903\n",
      "   macro avg       0.79      0.79      0.79      8903\n",
      "weighted avg       0.79      0.79      0.79      8903\n",
      "\n",
      "F1 SCORE:  0.7913406139994063\n",
      "Classificador: LogisticRegression \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      4470\n",
      "           1       0.89      0.90      0.90      4433\n",
      "\n",
      "    accuracy                           0.90      8903\n",
      "   macro avg       0.90      0.90      0.90      8903\n",
      "weighted avg       0.90      0.90      0.90      8903\n",
      "\n",
      "F1 SCORE:  0.8954244437468077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/CustomEnvironments/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "compare_models(X_train_count_vec_lemma, y_train, X_test_count_vec_lemma, y_test, [rf, gbc, abc, ls])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação de modelos utilizando TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador: RandomForestClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      4470\n",
      "           1       0.80      0.83      0.82      4433\n",
      "\n",
      "    accuracy                           0.81      8903\n",
      "   macro avg       0.81      0.81      0.81      8903\n",
      "weighted avg       0.81      0.81      0.81      8903\n",
      "\n",
      "F1 SCORE:  0.8120076376495514\n",
      "Classificador: GradientBoostingClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.54      0.65      4470\n",
      "           1       0.65      0.88      0.75      4433\n",
      "\n",
      "    accuracy                           0.71      8903\n",
      "   macro avg       0.74      0.71      0.70      8903\n",
      "weighted avg       0.74      0.71      0.70      8903\n",
      "\n",
      "F1 SCORE:  0.6992092442217015\n",
      "Classificador: AdaBoostClassifier \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      4470\n",
      "           1       0.78      0.83      0.80      4433\n",
      "\n",
      "    accuracy                           0.80      8903\n",
      "   macro avg       0.80      0.80      0.80      8903\n",
      "weighted avg       0.80      0.80      0.80      8903\n",
      "\n",
      "F1 SCORE:  0.7959344755133991\n",
      "Classificador: LogisticRegression \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      4470\n",
      "           1       0.87      0.90      0.89      4433\n",
      "\n",
      "    accuracy                           0.89      8903\n",
      "   macro avg       0.89      0.89      0.89      8903\n",
      "weighted avg       0.89      0.89      0.89      8903\n",
      "\n",
      "F1 SCORE:  0.8872010191172336\n"
     ]
    }
   ],
   "source": [
    "compare_models(X_train_id_vec_lemma, y_train, X_test_id_vec_lemma, y_test, [rf, gbc, abc, ls])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tivemos uma leve melhora na acurácia e F1-score dos modelos que utilizaram as features no formato TfidfVectorizer, porém, a Regressão Logistica teve a acurácia e f1-score de aproximadamente 90% utilizando CountVectorizer. Entre utilizar lematização, ou não, não fez tanta diferença na performance dos modelos escolhidos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CustomEnvironments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4aabb88045435d349253dee9475f1b8f1d18d926eaa18aec263db52c9fe6629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
